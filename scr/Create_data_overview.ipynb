{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8adfbea-0c07-4093-9d14-048c226091de",
   "metadata": {},
   "source": [
    "# Create overview of data\n",
    "\n",
    "Goal:\n",
    "\n",
    "* Create an overview table of all texts with the following info:\n",
    "    * document title\n",
    "    * document id (create unique id)\n",
    "    * language\n",
    "    * event type id\n",
    "    * incident id\n",
    "    * annotation status (manual, automatic, not)\n",
    "* Sort and store files using identifiers instead of document titles\n",
    "* Write conversion scripts from naf to:\n",
    "    * conll\n",
    "    * json (see what is convenient - look at hugging face input formats)\n",
    "    \n",
    "    \n",
    "**Step 1**\n",
    "\n",
    "Downloaded all repositories mentioned in our [data overview](https://docs.google.com/document/d/1uH1MawK5HVh1SkrD9qe-7A-hDfFAT-TYbkucIckPVGQ/edit?usp=sharing) (excluding Sam's Google drive updates) and stored in data/releases-and-repos. \n",
    "\n",
    "\n",
    "**Step 2**\n",
    "\n",
    "Sorted all repositories so that data are stored in the same dir structure: \n",
    "\n",
    "* unstructured/[lang]/docs.naf\n",
    "* unstructured/... (if present)\n",
    "\n",
    "Copied data to releases-and-repos-sorted following the structure outliend above. Observations:\n",
    "\n",
    "* typical_frames: no new data in  (downloades from DFNDataReleases) --> skipped\n",
    "* HDD_analysis: also downloaded from DFNDataReleases but some files found in test --> added\n",
    "* dfn-data-cleaning: contains two products:\n",
    "    * data-headlines --> integrated as dfn-data-cleaning-headlines-labeled\n",
    "    * data-headlines-unlabeled --> integrated as dfn-data-cleaning-headlines-unlabeled\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eeed663f-5cee-453e-a1e7-91ceb30247b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from lxml import etree as et\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efb6e53d-29ab-4475-aff7-423c2a6aff02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/piasommerauer/Code/DutchFrameNetData/scr'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ef73231-d35e-42b9-8e6c-b6f5ba720879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lxml.etree.XMLSyntaxError"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fcfaaec-fafe-4cfa-843e-e5f52c2ca37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at dir structures\n",
    "\n",
    "data_dir = '../data/releases-and-repos-sorted'\n",
    "\n",
    "all_paths = []\n",
    "\n",
    "for subdir in os.listdir(data_dir):\n",
    "    if not subdir.startswith('.DS'):\n",
    "        all_paths.append(f'{data_dir}/{subdir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76573a91-f008-4b3b-8d4a-c646a9e65e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/releases-and-repos-sorted/v1',\n",
       " '../data/releases-and-repos-sorted/dfn-data-cleaning-headlines-unlabeled',\n",
       " '../data/releases-and-repos-sorted/v2.1',\n",
       " '../data/releases-and-repos-sorted/v1.1',\n",
       " '../data/releases-and-repos-sorted/DFNDataReleases',\n",
       " '../data/releases-and-repos-sorted/DFN_annotations',\n",
       " '../data/releases-and-repos-sorted/HDD_analysis',\n",
       " '../data/releases-and-repos-sorted/v1.2',\n",
       " '../data/releases-and-repos-sorted/dfn-data-cleaning-headlines-labeled']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dddc67d-1109-4366-bc10-0a81c1af71c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'xml syntax error'}, '-', {})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if annotated\n",
    "\n",
    "def get_annotation_status(path):\n",
    "    \n",
    "    ann_time_dict = dict()\n",
    "\n",
    "    try: \n",
    "        tree = et.parse(path)\n",
    "        root = tree.getroot()\n",
    "        srl = root.find('srl')\n",
    "        timestamp = root.find('nafHeader/fileDesc').get('creationtime')\n",
    "        annotation_srl = [el for el in root.findall('nafHeader/linguisticProcessors') if el.get('layer') == 'srl']\n",
    "        if len(annotation_srl) > 0:\n",
    "        # get annotators and timestamps\n",
    "        \n",
    "            annotators = annotation_srl[0].findall('lp')\n",
    "            for an in annotators:\n",
    "                name = an.get('name')\n",
    "                ts = an.get('endTimestamp')\n",
    "                ann_time_dict[name] = ts\n",
    "        \n",
    "   \n",
    "    \n",
    "        if not srl is None:\n",
    "\n",
    "            preds = srl.findall('predicate')\n",
    "            annotation_mode = set()\n",
    "            for pred in preds:\n",
    "                annotation_mode.add(pred.get('status'))\n",
    "        else:\n",
    "            annotation_mode = {'none'}\n",
    "            \n",
    "        \n",
    "    except et.XMLSyntaxError:\n",
    "        annotation_mode = {'xml syntax error'}\n",
    "        timestamp = '-'\n",
    "\n",
    "        \n",
    "    \n",
    "    return annotation_mode, timestamp, ann_time_dict\n",
    "\n",
    "    \n",
    "test = all_paths[5]\n",
    "get_annotation_status(test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d5eae71-8fa0-41b7-a19a-5b21b6abc29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_recent_annotation(ann_time_dict):\n",
    "    \n",
    "    if len(ann_time_dict) > 0:\n",
    "    \n",
    "        times = list(ann_time_dict.values())\n",
    "        most_recent = max(times)\n",
    "\n",
    "        for name, ts in ann_time_dict.items():\n",
    "            if ts == most_recent:\n",
    "                latest_name = name\n",
    "                break\n",
    "    else:\n",
    "        most_recent = '-'\n",
    "        latest_name = '-'\n",
    "    return most_recent, latest_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34cf1fd7-1b40-4c92-b214-4da6408fefd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get quick overview\n",
    "\n",
    "doc_names = []\n",
    "full_paths = []\n",
    "langs = ['en', 'nl']\n",
    "\n",
    "for path in all_paths:\n",
    "    path_l = path.split('/')\n",
    "    source = path_l[-1]\n",
    "    for lang in langs:\n",
    "        path_lang = f'{path}/unstructured/{lang}/'\n",
    "        if os.path.isdir(path_lang):\n",
    "            for path_text in os.listdir(path_lang):\n",
    "                if path_text.endswith('.naf'):\n",
    "                    full_path = f'{path_lang}{path_text}'\n",
    "                    full_paths.append(full_path)\n",
    "                    ann_mode, timestamp, name_time_dict = get_annotation_status(full_path)\n",
    "                    most_recent, latest_name = get_most_recent_annotation(name_time_dict)\n",
    "                    title = path_text.split('.')[0].strip()\n",
    "                    d = dict()\n",
    "                    d['release'] = source\n",
    "                    d['lang'] = lang\n",
    "                    d['text_title'] = path_text\n",
    "                    d['annotation_mode'] = '-'.join(ann_mode)\n",
    "                    d['most_recent_annotation'] = most_recent\n",
    "                    d['most_recent_annotator'] = latest_name\n",
    "                    d['annotators'] = ' '.join(name_time_dict.keys())\n",
    "                    d['creationtime'] = timestamp\n",
    "                    doc_names.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1bd5d3f-87d8-4519-9b0e-d82f885b980f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['release', 'lang', 'text_title', 'annotation_mode', 'most_recent_annotation', 'most_recent_annotator', 'annotators', 'creationtime'])\n"
     ]
    }
   ],
   "source": [
    "header = doc_names[0].keys()\n",
    "print(header)\n",
    "with open('../data/overview.csv', 'w') as outfile:\n",
    "    writer = csv.DictWriter(outfile, fieldnames = header, delimiter = ',')\n",
    "    writer.writeheader()\n",
    "    for row in doc_names:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7911213-d48d-4ab0-b06e-c1952a8a8cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
